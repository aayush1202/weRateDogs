{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report is to describe the data wrangling process followed in the 'wrangle_act.ipynb' file. This project is part of the Udacity Nano Degree on Data Analysis. \n",
    "\n",
    "**Task**: To perform data wrangling on the data from the Twitter account of WeRateDogs. \n",
    "\n",
    "**Data Gathering**: I had to gather data from three different sources, as mandated in the project description. The first method was to gather data from a downloaded CSV file, from the Udacity resources. The second data source was a TSV file, which had to be retrieved using a URL provided in the project description on Udacity. This retrieval was done using the requests library to download the file programatically. For the third method of data collection, I had to use the Tweepy API to retrieve additional data in JSON format into a .txt file. I tried performing this task, but the Tweepy API did not return any results using the configuration provided by Udacity, so I used the 'tweet-json copy' file provided in the Udacity resources to get this data. \n",
    "\n",
    "**Data Cleaning**: I had to assess the data to find out 8 quality issues and 2 tidiness issues in the data gathered. I performed two types of assessment in this process - visual and programmatic. The twitter_archive dataframe had some issues related to data types of certain columns, along with containing data related to retweets, which isn't required. Similar issues related to retweets were present in tweet_images and tweet_data dataframes as well. \n",
    "\n",
    "**Cleaning Data**: The process for cleaning the dataframes started by making copies of the dataframes initially. The cleaning process involved multiple iterations of addressing each issue (quality and tidiness) in the following steps:\n",
    "* Defining the cleaning process\n",
    "* Peforming the cleaning action\n",
    "* Testing the results of the cleaning\n",
    "\n",
    "Initially I trimmed down the data by removing the data related to retweets, as it could also remove some other issues listed. I followed this by making the datasets tidy, and fixing the data types of the columns mentioned in the assessment process. \n",
    "\n",
    "**Storing Data**: Once the data was cleaned, I stored the final datasets in two different .csv files. \n",
    "\n",
    "**Analyzing and Visualizing Data**: The final datasets were used to gather some insights. The following conclusions were generated:\n",
    "* The number of tweets by the We Rate Dogs Twitter account peeked in Dec 2015.\n",
    "* The most popular dog based on the number of tweets is the golder retriever. \n",
    "* Pomerians are the highest rated dogs, among the the top 15 most tweeted dog breeds. \n",
    "\n",
    "These conclusions are based on the data available with us, and may vary if the analysis is done on an extended dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
